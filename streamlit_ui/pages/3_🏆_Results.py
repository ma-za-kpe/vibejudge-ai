"""Results page for viewing hackathon leaderboard and submission rankings.

This page allows organizers to:
- Select a hackathon from a dropdown
- View leaderboard with ranked submissions
- See summary statistics (total_submissions, analyzed_count)
- View detailed submission information
"""

import logging

import streamlit as st
from components.api_client import APIClient, APIError
from components.auth import is_authenticated
from components.retry_helpers import retry_button

logger = logging.getLogger(__name__)


# Page configuration
st.set_page_config(page_title="Results", page_icon="ğŸ†", layout="wide")


# Authentication check
if not is_authenticated():
    st.error("ğŸ”’ Please authenticate first")
    st.info("Go to the Home page to log in with your API key.")
    st.stop()


# Initialize API client
api_client = APIClient(st.session_state["api_base_url"], st.session_state["api_key"])


# Page header
st.title("ğŸ† Results")
st.markdown("View ranked submissions and leaderboard for your hackathon.")


# Initialize view mode in session state
if "view_mode" not in st.session_state:
    st.session_state["view_mode"] = "leaderboard"


# Cached function to fetch hackathons list
@st.cache_data(ttl=30)
def fetch_hackathons(api_key: str) -> list[dict]:
    """Fetch list of hackathons from the backend.

    Args:
        api_key: The API key for authentication (used as cache key)

    Returns:
        List of hackathon dictionaries
    """
    client = APIClient(st.session_state["api_base_url"], api_key)
    try:
        response = client.get("/hackathons")
        return response if isinstance(response, list) else []
    except APIError as e:
        logger.error(f"Failed to fetch hackathons: {e}")
        st.error(f"âŒ Failed to fetch hackathons: {e}")
        retry_button(lambda: st.cache_data.clear() or st.rerun(), "ğŸ”„ Retry Loading Hackathons")
        return []


# Cached function to fetch leaderboard
@st.cache_data(ttl=30)
def fetch_leaderboard(api_key: str, hack_id: str) -> dict | None:
    """Fetch leaderboard for a specific hackathon.

    Args:
        api_key: The API key for authentication (used as cache key)
        hack_id: The hackathon ID

    Returns:
        Dictionary containing leaderboard data or None if error occurred
    """
    client = APIClient(st.session_state["api_base_url"], api_key)
    try:
        return client.get(f"/hackathons/{hack_id}/leaderboard")
    except APIError as e:
        logger.error(f"Failed to fetch leaderboard for {hack_id}: {e}")
        st.error(f"âŒ Failed to fetch leaderboard: {e}")
        retry_button(lambda: st.cache_data.clear() or st.rerun(), "ğŸ”„ Retry Loading Leaderboard")
        return None


# Check if we're in team detail view mode
if st.session_state["view_mode"] == "team_detail":
    # Display back button
    if st.button("â¬…ï¸ Back to Leaderboard"):
        st.session_state["view_mode"] = "leaderboard"
        st.rerun()

    # Get selected submission ID
    if "selected_sub_id" not in st.session_state:
        st.error("âŒ No submission selected")
        st.stop()

    sub_id = st.session_state["selected_sub_id"]
    hack_id = st.session_state.get("selected_hackathon", "")

    if not hack_id:
        st.error("âŒ No hackathon selected")
        st.stop()

    # Cached function to fetch scorecard
    @st.cache_data(ttl=30)
    def fetch_scorecard(api_key: str, hack_id: str, sub_id: str) -> dict | None:
        """Fetch scorecard for a specific submission.

        Args:
            api_key: The API key for authentication (used as cache key)
            hack_id: The hackathon ID
            sub_id: The submission ID

        Returns:
            Dictionary containing scorecard data or None if error occurred
        """
        client = APIClient(st.session_state["api_base_url"], api_key)
        try:
            return client.get(f"/hackathons/{hack_id}/submissions/{sub_id}/scorecard")
        except APIError as e:
            logger.error(f"Failed to fetch scorecard for {sub_id}: {e}")
            st.error(f"âŒ Failed to fetch scorecard: {e}")
            retry_button(lambda: st.cache_data.clear() or st.rerun(), "ğŸ”„ Retry Loading Scorecard")
            return None

    # Fetch scorecard data
    with st.spinner("ğŸ“‹ Loading scorecard..."):
        scorecard = fetch_scorecard(st.session_state["api_key"], hack_id, sub_id)

    if not scorecard:
        st.error("âŒ Failed to load scorecard. Please try again.")
        st.stop()

    # Display team detail scorecard
    st.subheader(f"ğŸ“‹ Scorecard: {scorecard.get('team_name', 'Unknown Team')}")

    # Create tabs for organizing scorecard content
    tab1, tab2, tab3, tab4 = st.tabs(
        ["ğŸ“Š Overview", "ğŸ¤– Agent Analysis", "ğŸ“¦ Repository", "ğŸ‘¥ Team Members"]
    )

    with tab1:
        # Overall metrics section
        st.markdown("### ğŸ¯ Overall Evaluation")

        col1, col2, col3 = st.columns(3)

        with col1:
            overall_score = scorecard.get("overall_score", 0)
            st.metric(
                label="Overall Score",
                value=f"{overall_score:.1f}",
                help="Weighted average score across all dimensions",
            )

        with col2:
            confidence = scorecard.get("confidence", 0)
            st.metric(
                label="Confidence",
                value=f"{confidence:.0%}",
                help="AI confidence in the evaluation",
            )

        with col3:
            recommendation = scorecard.get("recommendation", "N/A").replace("_", " ").title()
            st.metric(
                label="Recommendation",
                value=recommendation,
                help="Hiring recommendation based on evaluation",
            )

        # Dimension scores section
        st.markdown("---")
        st.markdown("### ğŸ“Š Dimension Scores")

        dimension_scores = scorecard.get("dimension_scores", {})

        if dimension_scores:
            # Create table header
            header_col1, header_col2, header_col3, header_col4 = st.columns([2, 1, 1, 1])
            with header_col1:
                st.markdown("**Dimension**")
            with header_col2:
                st.markdown("**Raw Score**")
            with header_col3:
                st.markdown("**Weight**")
            with header_col4:
                st.markdown("**Weighted Score**")

            st.divider()

            # Display each dimension
            for dimension_name, scores in dimension_scores.items():
                col1, col2, col3, col4 = st.columns([2, 1, 1, 1])

                with col1:
                    # Format dimension name (e.g., "code_quality" -> "Code Quality")
                    formatted_name = dimension_name.replace("_", " ").title()
                    st.markdown(formatted_name)

                with col2:
                    raw_score = scores.get("raw", 0)
                    st.markdown(f"{raw_score:.1f}")

                with col3:
                    weight = scores.get("weight", 0)
                    st.markdown(f"{weight:.0%}")

                with col4:
                    weighted_score = scores.get("weighted", 0)
                    st.markdown(f"{weighted_score:.1f}")

                st.divider()
        else:
            st.info("ğŸ“­ No dimension scores available")

        # Cost breakdown section
        st.markdown("---")
        st.markdown("### ğŸ’° Cost Breakdown")

        total_cost_usd = scorecard.get("total_cost_usd", 0)

        st.metric(
            label="Total Analysis Cost",
            value=f"${total_cost_usd:.4f}",
            help="Total cost for analyzing this submission",
        )

        # Display cost by agent
        agent_results = scorecard.get("agent_results", {})
        if agent_results:
            with st.expander("View Cost by Agent"):
                for agent_name, result in agent_results.items():
                    formatted_agent_name = agent_name.replace("_", " ").title()
                    cost_usd = result.get("cost_usd", 0)
                    st.caption(f"- {formatted_agent_name}: ${cost_usd:.4f}")

    with tab2:
        # Agent results section
        st.markdown("### ğŸ¤– Agent Analysis")

        agent_results = scorecard.get("agent_results", {})

        if agent_results:
            for agent_name, result in agent_results.items():
                # Format agent name (e.g., "bug_hunter" -> "Bug Hunter")
                formatted_agent_name = agent_name.replace("_", " ").title()

                with st.expander(f"**{formatted_agent_name}**", expanded=False):
                    # Summary
                    summary = result.get("summary", "N/A")
                    st.markdown("**Summary:**")
                    st.markdown(summary)

                    st.markdown("")

                    # Strengths
                    strengths = result.get("strengths", [])
                    if strengths:
                        st.markdown("**âœ… Strengths:**")
                        for strength in strengths:
                            st.markdown(f"- {strength}")
                        st.markdown("")

                    # Improvements
                    improvements = result.get("improvements", [])
                    if improvements:
                        st.markdown("**ğŸ’¡ Areas for Improvement:**")
                        for improvement in improvements:
                            st.markdown(f"- {improvement}")
                        st.markdown("")

                    # Cost
                    cost_usd = result.get("cost_usd", 0)
                    st.caption(f"Analysis cost: ${cost_usd:.4f}")
        else:
            st.info("ğŸ“­ No agent results available")

    with tab3:
        # Repository metadata section
        st.markdown("### ğŸ“¦ Repository Metadata")

        repo_meta = scorecard.get("repo_meta", {})

        if repo_meta:
            col1, col2, col3, col4, col5 = st.columns(5)

            with col1:
                primary_language = repo_meta.get("primary_language", "N/A")
                st.metric(
                    label="Primary Language",
                    value=primary_language,
                    help="Main programming language used",
                )

            with col2:
                commit_count = repo_meta.get("commit_count", 0)
                st.metric(label="Commits", value=commit_count, help="Total number of commits")

            with col3:
                contributor_count = repo_meta.get("contributor_count", 0)
                st.metric(
                    label="Contributors",
                    value=contributor_count,
                    help="Number of unique contributors",
                )

            with col4:
                has_tests = repo_meta.get("has_tests", False)
                test_status = "âœ… Yes" if has_tests else "âŒ No"
                st.metric(
                    label="Has Tests",
                    value=test_status,
                    help="Whether the repository includes tests",
                )

            with col5:
                has_ci = repo_meta.get("has_ci", False)
                ci_status = "âœ… Yes" if has_ci else "âŒ No"
                st.metric(
                    label="Has CI/CD",
                    value=ci_status,
                    help="Whether the repository has CI/CD configured",
                )
        else:
            st.info("ğŸ“­ No repository metadata available")

    with tab4:
        # Individual team member scorecard section
        st.markdown("### ğŸ‘¥ Individual Team Member Analysis")

        # Cached function to fetch individual scorecards
        @st.cache_data(ttl=30)
        def fetch_individual_scorecards(api_key: str, hack_id: str, sub_id: str) -> dict | None:
            """Fetch individual scorecards for a specific submission.

            Args:
                api_key: The API key for authentication (used as cache key)
                hack_id: The hackathon ID
                sub_id: The submission ID

            Returns:
                Dictionary containing individual scorecard data or None if error occurred
            """
            client = APIClient(st.session_state["api_base_url"], api_key)
            try:
                return client.get(
                    f"/hackathons/{hack_id}/submissions/{sub_id}/individual-scorecards"
                )
            except APIError as e:
                logger.error(f"Failed to fetch individual scorecards for {sub_id}: {e}")
                # Return None to indicate data is unavailable (not an error to display)
                return None

        # Fetch individual scorecard data
        with st.spinner("ğŸ‘¥ Loading individual team member analysis..."):
            individual_data = fetch_individual_scorecards(
                st.session_state["api_key"], hack_id, sub_id
            )

        if not individual_data:
            st.info(
                "ğŸ“­ Individual team member analysis is pending or unavailable. This data will be available after the analysis is complete."
            )
        else:
            # Team dynamics section
            team_dynamics = individual_data.get("team_dynamics", {})

        if team_dynamics:
            st.markdown("#### ğŸ¤ Team Dynamics")

            col1, col2, col3 = st.columns(3)

            with col1:
                collaboration_quality = team_dynamics.get("collaboration_quality", "N/A")
                st.metric(
                    label="Collaboration Quality",
                    value=collaboration_quality.title()
                    if isinstance(collaboration_quality, str)
                    else "N/A",
                    help="Assessment of how well the team worked together",
                )

            with col2:
                role_distribution = team_dynamics.get("role_distribution", "N/A")
                st.metric(
                    label="Role Distribution",
                    value=role_distribution.title()
                    if isinstance(role_distribution, str)
                    else "N/A",
                    help="How roles were distributed among team members",
                )

            with col3:
                communication_patterns = team_dynamics.get("communication_patterns", "N/A")
                st.metric(
                    label="Communication Patterns",
                    value=communication_patterns.title()
                    if isinstance(communication_patterns, str)
                    else "N/A",
                    help="Quality and frequency of team communication",
                )

        # Strategy analysis section
        strategy_analysis = individual_data.get("strategy_analysis", {})

        if strategy_analysis:
            st.markdown("#### ğŸ¯ Strategy Analysis")

            col1, col2, col3 = st.columns(3)

            with col1:
                development_approach = strategy_analysis.get("development_approach", "N/A")
                st.metric(
                    label="Development Approach",
                    value=development_approach.title()
                    if isinstance(development_approach, str)
                    else "N/A",
                    help="The team's approach to development",
                )

            with col2:
                time_management = strategy_analysis.get("time_management", "N/A")
                st.metric(
                    label="Time Management",
                    value=time_management.title() if isinstance(time_management, str) else "N/A",
                    help="How well the team managed their time",
                )

            with col3:
                risk_management = strategy_analysis.get("risk_management", "N/A")
                st.metric(
                    label="Risk Management",
                    value=risk_management.title() if isinstance(risk_management, str) else "N/A",
                    help="The team's approach to managing risks",
                )

        # Contributors section
        contributors = individual_data.get("contributors", [])

        if contributors:
            st.markdown("#### ğŸ‘¤ Individual Contributors")

            # Display each contributor
            for contributor in contributors:
                member_name = contributor.get("member_name", "Unknown")
                commit_count = contributor.get("commit_count", 0)
                skill_assessment = contributor.get("skill_assessment", "N/A")
                actionable_feedback = contributor.get("actionable_feedback", "")

                with st.expander(f"**{member_name}**", expanded=False):
                    # Contributor metrics
                    col1, col2 = st.columns(2)

                    with col1:
                        st.metric(
                            label="Commits",
                            value=commit_count,
                            help="Number of commits by this contributor",
                        )

                    with col2:
                        st.metric(
                            label="Skill Assessment",
                            value=skill_assessment.title()
                            if isinstance(skill_assessment, str)
                            else "N/A",
                            help="Assessed skill level of this contributor",
                        )

                    # Actionable feedback
                    if actionable_feedback:
                        st.markdown("**ğŸ’¡ Actionable Feedback:**")
                        st.markdown(actionable_feedback)
                    else:
                        st.info("No actionable feedback available for this contributor.")
        else:
            st.info("ğŸ“­ No individual contributor data available")

    st.stop()


# Continue with leaderboard view


# Fetch hackathons for dropdown
with st.spinner("ğŸ”„ Loading hackathons..."):
    hackathons = fetch_hackathons(st.session_state["api_key"])

# Filter out DRAFT and ARCHIVED hackathons (only show CONFIGURED, ANALYZING, COMPLETED)
active_hackathons = [
    h for h in hackathons 
    if h.get("status") not in ["draft", "archived"]
]

# Display hackathon selection dropdown
if not active_hackathons:
    st.warning("âš ï¸ No active hackathons found.")
    st.info("ğŸ’¡ Create a hackathon and activate it to start accepting submissions.")
    st.stop()


# Create dropdown with hackathon names
hackathon_options = {h["name"]: h["hack_id"] for h in active_hackathons}
selected_name = st.selectbox(
    "Select Hackathon",
    options=list(hackathon_options.keys()),
    help="Choose a hackathon to view its leaderboard",
)


# Get selected hackathon ID
selected_hack_id = hackathon_options[selected_name]


# Store selected hackathon in session state
st.session_state["selected_hackathon"] = selected_hack_id


# Fetch and display leaderboard
st.markdown("---")


with st.spinner("ğŸ† Loading leaderboard..."):
    leaderboard_data = fetch_leaderboard(st.session_state["api_key"], selected_hack_id)


if leaderboard_data:
    # Display summary statistics
    total_submissions = leaderboard_data.get("total_submissions", 0)
    analyzed_count = leaderboard_data.get("analyzed_count", 0)

    st.subheader("ğŸ“Š Summary")

    col1, col2 = st.columns(2)

    with col1:
        st.metric(
            label="Total Submissions",
            value=total_submissions,
            help="Total number of submissions received",
        )

    with col2:
        st.metric(
            label="Analyzed Submissions",
            value=analyzed_count,
            help="Number of submissions that have been analyzed",
        )

    # Display leaderboard table
    st.markdown("---")
    st.subheader("ğŸ… Leaderboard")

    submissions = leaderboard_data.get("submissions", [])

    if not submissions:
        st.info("ğŸ“­ No submissions have been analyzed yet.")
        st.caption("Start an analysis from the Live Dashboard to generate results.")
    else:
        # Search and sort controls
        col1, col2 = st.columns([2, 1])

        with col1:
            search_query = st.text_input(
                "ğŸ” Search by team name",
                placeholder="Enter team name...",
                help="Filter submissions by team name (case-insensitive)",
                key="search_query_input",
            )

        with col2:
            sort_option = st.selectbox(
                "Sort by",
                options=["score", "team_name", "created_at"],
                format_func=lambda x: {
                    "score": "Overall Score",
                    "team_name": "Team Name",
                    "created_at": "Submission Date",
                }[x],
                help="Sort leaderboard by selected field",
                key="sort_option_select",
            )

        # Reset page number when search or sort changes
        if "last_search_query" not in st.session_state:
            st.session_state["last_search_query"] = ""
        if "last_sort_option" not in st.session_state:
            st.session_state["last_sort_option"] = "score"

        if (
            search_query != st.session_state["last_search_query"]
            or sort_option != st.session_state["last_sort_option"]
        ):
            st.session_state["results_page_number"] = 1
            st.session_state["last_search_query"] = search_query
            st.session_state["last_sort_option"] = sort_option

        # Apply search filter (case-insensitive)
        filtered_submissions = submissions
        if search_query:
            filtered_submissions = [
                s for s in submissions if search_query.lower() in s.get("team_name", "").lower()
            ]

        # Apply sorting
        if sort_option == "score":
            # Sort by overall_score descending (highest first)
            filtered_submissions = sorted(
                filtered_submissions, key=lambda x: x.get("overall_score", 0), reverse=True
            )
        elif sort_option == "team_name":
            # Sort by team_name ascending (A-Z)
            filtered_submissions = sorted(
                filtered_submissions, key=lambda x: x.get("team_name", "").lower()
            )
        elif sort_option == "created_at":
            # Sort by created_at descending (newest first)
            filtered_submissions = sorted(
                filtered_submissions, key=lambda x: x.get("created_at", ""), reverse=True
            )

        # Display filtered and sorted results
        if not filtered_submissions:
            st.warning(f"âš ï¸ No submissions found matching '{search_query}'")
        else:
            # Pagination setup
            ITEMS_PER_PAGE = 50
            total_items = len(filtered_submissions)
            total_pages = (total_items + ITEMS_PER_PAGE - 1) // ITEMS_PER_PAGE  # Ceiling division

            # Initialize page number in session state
            if "results_page_number" not in st.session_state:
                st.session_state["results_page_number"] = 1

            # Ensure page number is within valid range
            if st.session_state["results_page_number"] > total_pages:
                st.session_state["results_page_number"] = total_pages
            if st.session_state["results_page_number"] < 1:
                st.session_state["results_page_number"] = 1

            current_page = st.session_state["results_page_number"]

            # Calculate pagination slice
            start_idx = (current_page - 1) * ITEMS_PER_PAGE
            end_idx = min(start_idx + ITEMS_PER_PAGE, total_items)
            paginated_submissions = filtered_submissions[start_idx:end_idx]

            # Display table header
            header_col1, header_col2, header_col3, header_col4, header_col5 = st.columns(
                [0.5, 2, 1, 1.5, 1]
            )
            with header_col1:
                st.markdown("**Rank**")
            with header_col2:
                st.markdown("**Team Name**")
            with header_col3:
                st.markdown("**Score**")
            with header_col4:
                st.markdown("**Recommendation**")
            with header_col5:
                st.markdown("**Actions**")

            st.divider()

            # Display submissions as clickable rows
            for submission in paginated_submissions:
                rank = submission.get("rank", "N/A")
                team_name = submission.get("team_name", "Unknown")
                overall_score = submission.get("overall_score", 0)
                recommendation = submission.get("recommendation", "N/A").replace("_", " ").title()
                sub_id = submission.get("sub_id", "")

                # Create a container for each row
                col1, col2, col3, col4, col5 = st.columns([0.5, 2, 1, 1.5, 1])

                with col1:
                    st.markdown(f"{rank}")

                with col2:
                    st.markdown(f"{team_name}")

                with col3:
                    st.markdown(f"{overall_score:.1f}")

                with col4:
                    st.markdown(f"{recommendation}")

                with col5:
                    # Make the row clickable with a button
                    if st.button("View Details", key=f"view_{sub_id}"):
                        # Store selected sub_id in session state
                        st.session_state["selected_sub_id"] = sub_id
                        st.session_state["view_mode"] = "team_detail"
                        st.rerun()

                st.divider()

            # Pagination controls
            if total_pages > 1:
                col1, col2, col3, col4, col5 = st.columns([1, 1, 2, 1, 1])

                with col1:
                    if st.button("â®ï¸ First", disabled=(current_page == 1)):
                        st.session_state["results_page_number"] = 1
                        st.rerun()

                with col2:
                    if st.button("â—€ï¸ Previous", disabled=(current_page == 1)):
                        st.session_state["results_page_number"] = current_page - 1
                        st.rerun()

                with col3:
                    st.markdown(
                        f"<div style='text-align: center; padding: 5px;'>Page {current_page} of {total_pages}</div>",
                        unsafe_allow_html=True,
                    )

                with col4:
                    if st.button("Next â–¶ï¸", disabled=(current_page == total_pages)):
                        st.session_state["results_page_number"] = current_page + 1
                        st.rerun()

                with col5:
                    if st.button("Last â­ï¸", disabled=(current_page == total_pages)):
                        st.session_state["results_page_number"] = total_pages
                        st.rerun()

            st.caption(f"Showing {start_idx + 1}-{end_idx} of {total_items} submission(s)")

else:
    st.error("âŒ Failed to load leaderboard. Please try again.")
    retry_button(lambda: st.cache_data.clear() or st.rerun(), "ğŸ”„ Retry Loading Leaderboard")


# Manual refresh button
st.markdown("---")
if st.button("ğŸ”„ Refresh"):
    # Clear cache to force refresh
    st.cache_data.clear()
    st.rerun()
